{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DineshThumma9/silver-doodle/blob/main/fixed_LLamaIndexRAGAdv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXg3erogoO5Z"
      },
      "outputs": [],
      "source": [
        "%pip install -Uq llama-index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcBrwQAYotBv"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYmsMecfoc-9"
      },
      "outputs": [],
      "source": [
        "%pip install llama-index-llms\n",
        "%pip install llama-index-embeddings-huggingface\n",
        "%pip install nest_asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMio-_fapORM"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOuzPXY4pbIb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kYfqGHmqAe0"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "%time\n",
        "docs = SimpleDirectoryReader(input_dir=\"./data\").load_data()\n",
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wRjkMjzdr1lI"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "pprint.pprint(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dN29CDHEbMS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHgCyiBpsO8_"
      },
      "outputs": [],
      "source": [
        "docs[0].__dict__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIBspH45s2Pm"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import Document\n",
        "from llama_index.core.schema import MetadataMode\n",
        "\n",
        "\n",
        "document = Document(\n",
        "    text = \"This is a super-cutomization document\",\n",
        "    metadata = {\n",
        "        \"file_name\" : \"super_secret_document.txt\",\n",
        "         \"category\" : \"tech\",\n",
        "        \"author\" : \"LlamaIndex\"\n",
        "    },\n",
        "    # excluded_embed_metadata_keys = [\"file_name\"],\n",
        "    excluded_embed_llm_keys = [\"category\"],\n",
        "    metadata_template = \"{key}:{value}\",\n",
        "    metadata_separator = \"\\n\",\n",
        "    text_template=\"Metadata:\\n{metadata_str}\\n--------\\nContent:\\n{content}\",\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "print(\n",
        "\n",
        "     \"The embedding model sees this : \\n\",\n",
        "     document.get_content(metadata_mode=MetadataMode.EMBED) ,\n",
        "\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZp4gMzyzyeZ"
      },
      "outputs": [],
      "source": [
        "for doc in docs:\n",
        "\n",
        "  doc.text_template = \"Metadata:\\n{metadata_str}\\n-----\\nContent:\\n{content}\"\n",
        "\n",
        "  if \"page_label\" not in doc.excluded_embed_metadata_keys:\n",
        "    doc.excluded_embed_metadata_keys.append(\"page_label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NGcQT3S0AW_"
      },
      "outputs": [],
      "source": [
        "print(docs[0].get_content(metadata_mode=MetadataMode.EMBED))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JC2LOa-K1XPv"
      },
      "outputs": [],
      "source": [
        "%pip install -Uq llama-index-llms-groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2oFvZoS1-ea"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.groq import Groq\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Groq API Key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9GYRBAB2Ey_"
      },
      "outputs": [],
      "source": [
        "llm = Groq(model=\"qwen-2.5-32b\" , api_key=os.environ[\"GROQ_API_KEY\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8COmj6GJ2gb-"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.extractors import (\n",
        "    TitleExtractor,\n",
        "    QuestionsAnsweredExtractor\n",
        ")\n",
        "\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "text_splitter = SentenceSplitter(\n",
        "    separator=\" \",chunk_size = 1024 , chunk_overlap = 128\n",
        ")\n",
        "\n",
        "\n",
        "title_extractor = TitleExtractor(llm = llm ,nodes = 5)\n",
        "qa_extractor = QuestionsAnsweredExtractor(llm = llm,questions=3)\n",
        "\n",
        "from llama_index.core.ingestion import IngestionPipeline\n",
        "\n",
        "pipeline = IngestionPipeline(\n",
        "    transformations = [\n",
        "        text_splitter,\n",
        "        title_extractor,\n",
        "        qa_extractor\n",
        "\n",
        "    ]\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "nodes = pipeline.run(\n",
        "    documents = docs,\n",
        "    in_place = True,\n",
        "    show_progress = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Y-x3ZlBCgTH"
      },
      "outputs": [],
      "source": [
        "pprint.pprint(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaQ6uCgfHjxZ"
      },
      "outputs": [],
      "source": [
        "pprint.pprint(docs[0].__dict__)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}